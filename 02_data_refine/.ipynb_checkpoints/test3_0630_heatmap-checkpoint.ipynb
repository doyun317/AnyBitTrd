{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import vae as V\n",
    "\n",
    "def data_scaling(data):             #스케일러, main\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_sliding(data, n_features, Time_window): #데이터 밀기, main\n",
    "    # reshape_num = data.shape[0] - Time_window + 1\n",
    "    data = sliding_window_view(data, (Time_window, n_features))\n",
    "    #   data = data.reshape(reshape_num, Time_window, n_features) <-필요없음\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_load_processing(FILENAME, Time_window=None): #데이터 로딩 및 스케일러 사용, main\n",
    "    df = pd.read_csv(FILENAME)\n",
    "    df = df.drop(['Time'], axis=1)\n",
    "    n_features = df.shape[1]\n",
    "    x_train, x_test = train_test_split(df, test_size=0.9, shuffle=False)\n",
    "    #x_validation, x_test = train_test_split(x_test, test_size=0.5, shuffle=False)\n",
    "\n",
    "    x_train = data_scaling(x_train)\n",
    "    x_test = data_scaling(x_test)\n",
    "    #x_validation = data_scaling(x_validation)\n",
    "\n",
    "    x_train = data_sliding(x_train, n_features, Time_window)\n",
    "    x_test = data_sliding(x_test, n_features, Time_window)\n",
    "    #x_validation = data_sliding(x_validation, n_features, Time_window)\n",
    "\n",
    "    return x_train, x_test #, x_validation\n",
    "\n",
    "\n",
    "def sampling(inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "def vae_model(input_shape, latent_dim, kernel_size, strides, padding):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = layers.Conv2D(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv1\", data_format=\"channels_first\")(inputs)\n",
    "    h = layers.Conv2D(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv2\", data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2D(128, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv3\", data_format=\"channels_first\")(h)\n",
    "    shape_save = h.get_shape().as_list()\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Dense(16, activation=\"relu\")(h)\n",
    "\n",
    "    # vae\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(h)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(h)\n",
    "    z = sampling([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # decoder\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    h = layers.Dense(shape_save[1] * shape_save[2] * shape_save[3], activation=\"relu\")(latent_inputs)\n",
    "    h = layers.Reshape((shape_save[1], shape_save[2], shape_save[3]))(h)\n",
    "    h = layers.Conv2DTranspose(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2DTranspose(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1,kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                                             data_format=\"channels_first\")(h)\n",
    "    decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    return encoder, decoder\n",
    "\n",
    "def lstm_preprocess(latent_z, seq_length):\n",
    "    reshape_num = latent_z.shape[0] - seq_length + 1\n",
    "    slide_z = sliding_window_view(latent_z, (seq_length, latent_z.shape[1]))\n",
    "    slide_z = slide_z.reshape(reshape_num, seq_length, latent_z.shape[1])\n",
    "    slide_z = slide_z[:-1]\n",
    "\n",
    "    dataY = []\n",
    "    for i in range(0, len(latent_z) - seq_length):\n",
    "        _y = latent_z[i + seq_length]  # 다음 나타날 z(정답)\n",
    "        dataY.append(_y)  # dataY 리스트에 추가\n",
    "    dataY = np.array(dataY)\n",
    "    \n",
    "    return slide_z, dataY\n",
    "    \n",
    "    \n",
    "def lstm_model(seq_length, latent_dim, lstm_z):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(seq_length, latent_dim))\n",
    "    h = layers.LSTM(32, activation=\"relu\", name='lstm1')(inputs)\n",
    "    lstm_outputs = layers.Dense(latent_dim, activation='sigmoid')(h)\n",
    "    lstm = tf.keras.Model(inputs, lstm_outputs, name='lstm')\n",
    "    lstm.compile(loss='mse', optimizer=tf.keras.optimizers.Adam())\n",
    "    lstm.fit(lstm_z, dataY, epochs=5, batch_size=256)\n",
    "    lstm_results = lstm.predict(lstm_z)\n",
    "\n",
    "    return lstm_results\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    #---------------------------------사용자 설정 변수---------------------------------------\n",
    "    FILENAME = \"BTC_USDT.csv\"\n",
    "    Time_window = 8\n",
    "    latent_dim = 2\n",
    "    #-------------------------------------------------------------------------------------\n",
    "\n",
    "    #데이터 로딩\n",
    "    x_train, x_test= data_load_processing(FILENAME, Time_window=Time_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_shape, latent_dim, kernel_size, strides, padding):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = layers.Conv2D(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv1\", data_format=\"channels_first\")(inputs)\n",
    "    h = layers.Conv2D(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv2\", data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2D(128, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv3\", data_format=\"channels_first\")(h)\n",
    "    shape_save = h.get_shape().as_list()\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Dense(32, activation=\"relu\")(h)\n",
    "\n",
    "    # vae\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(h)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(h)\n",
    "    z = sampling([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # decoder\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    h = layers.Dense(shape_save[1] * shape_save[2] * shape_save[3], activation=\"relu\")(latent_inputs)\n",
    "    h = layers.Reshape((shape_save[1], shape_save[2], shape_save[3]))(h)\n",
    "    h = layers.Conv2DTranspose(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2DTranspose(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1,kernel_size=kernel_size, strides=strides, padding=padding, activation=\"relu\",\n",
    "                                             data_format=\"channels_first\")(h)\n",
    "    decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           10256       flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_18 (TFOpLamb (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_19 (TFOpLamb (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_18 (TFOpLambda (None, 2)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_18 (Sl ()                   0           tf.compat.v1.shape_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_19 (Sl ()                   0           tf.compat.v1.shape_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_9 (TFOpLambda)      (None, 2)            0           tf.math.multiply_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal_9 (TFOpLambda) (None, None)         0           tf.__operators__.getitem_18[0][0]\n",
      "                                                                 tf.__operators__.getitem_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_19 (TFOpLambda (None, 2)            0           tf.math.exp_9[0][0]              \n",
      "                                                                 tf.random.normal_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_19[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 92,724\n",
      "Trainable params: 92,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 640)               1920      \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 128, 1, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 64, 2, 12)         65600     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DT (None, 32, 4, 26)         16416     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DT (None, 1, 8, 54)          257       \n",
      "=================================================================\n",
      "Total params: 84,193\n",
      "Trainable params: 84,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "617/617 [==============================] - 6s 8ms/step - loss: 5.3794 - reconstruction_loss: 4.2983 - kl_loss: 0.0071\n",
      "Epoch 2/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.8013 - reconstruction_loss: 3.7977 - kl_loss: 6.0460e-04\n",
      "Epoch 3/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7950 - reconstruction_loss: 3.7952 - kl_loss: 1.7763e-04\n",
      "Epoch 4/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7950 - reconstruction_loss: 3.7951 - kl_loss: 5.8450e-05\n",
      "Epoch 5/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7959 - reconstruction_loss: 3.7952 - kl_loss: 2.9315e-05\n",
      "Epoch 6/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7967 - reconstruction_loss: 3.7954 - kl_loss: 2.5852e-05\n",
      "Epoch 7/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7962 - reconstruction_loss: 3.7953 - kl_loss: 1.7764e-06\n",
      "Epoch 8/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7964 - reconstruction_loss: 3.7955 - kl_loss: 1.0905e-07\n",
      "Epoch 9/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.8026 - reconstruction_loss: 3.7977 - kl_loss: 8.6211e-06\n",
      "Epoch 10/10\n",
      "617/617 [==============================] - 5s 8ms/step - loss: 3.7949 - reconstruction_loss: 3.7956 - kl_loss: 1.7061e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.816001192297826"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=256)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.92028172e-01, 2.90334511e-01, 2.94325406e-01, 2.91690876e-01,\n",
       "       1.28034781e-02, 2.91970143e-01, 1.70846712e-02, 2.91319238e-01,\n",
       "       2.01296969e-02, 4.47492299e-01, 2.36533311e-01, 3.66674647e-01,\n",
       "       3.92146587e-01, 2.91061150e-01, 2.12365833e-02, 2.91134819e-01,\n",
       "       2.79011400e-02, 3.60360194e-01, 1.27683809e-01, 3.65558665e-01,\n",
       "       2.11723599e-01, 2.91124649e-01, 3.42660671e-02, 2.90319558e-01,\n",
       "       2.98881262e-02, 3.48278646e-01, 6.07620474e-02, 3.35166460e-01,\n",
       "       1.17714478e-01, 2.85898890e-01, 2.37780000e-02, 2.85868523e-01,\n",
       "       3.21074999e-02, 2.99450752e-01, 5.12985089e-02, 2.97449067e-01,\n",
       "       6.24664374e-02, 2.82898658e-01, 5.55299442e-02, 2.84263507e-01,\n",
       "       4.31056906e-02, 3.02565338e-01, 2.62291760e-02, 3.02324704e-01,\n",
       "       4.48243776e-02, 5.33293333e-01, 3.61499602e-02, 9.99928230e-01,\n",
       "       5.65686608e-01, 4.23772617e-04, 4.13801998e-01, 2.49842430e-01,\n",
       "       9.89829098e-01, 3.75898567e-02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41564068, 0.41169715, 0.41704142, 0.41356954, 0.02114492,\n",
       "       0.41512644, 0.03634055, 0.41435286, 0.03930253, 0.4532826 ,\n",
       "       0.20820186, 0.38000414, 0.31874374, 0.41254085, 0.04463781,\n",
       "       0.4133929 , 0.05623243, 0.3718678 , 0.1125572 , 0.38314062,\n",
       "       0.17987633, 0.41097865, 0.06023536, 0.41346917, 0.05973134,\n",
       "       0.37840077, 0.06436364, 0.35687733, 0.10457884, 0.40675923,\n",
       "       0.0712724 , 0.41006956, 0.0755938 , 0.30367488, 0.04012398,\n",
       "       0.30660704, 0.05359644, 0.407118  , 0.09678193, 0.410569  ,\n",
       "       0.10092318, 0.3029166 , 0.0298253 , 0.30363297, 0.04078742,\n",
       "       0.5150257 , 0.02060512, 0.9681683 , 0.56641614, 0.        ,\n",
       "       0.4541178 , 0.5057374 , 0.47650972, 0.04984267], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_latent_z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
