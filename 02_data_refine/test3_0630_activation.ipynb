{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import vae as V\n",
    "\n",
    "def data_scaling(data):             #스케일러, main\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_sliding(data, n_features, Time_window): #데이터 밀기, main\n",
    "    # reshape_num = data.shape[0] - Time_window + 1\n",
    "    data = sliding_window_view(data, (Time_window, n_features))\n",
    "    #   data = data.reshape(reshape_num, Time_window, n_features) <-필요없음\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_load_processing(FILENAME, Time_window=None): #데이터 로딩 및 스케일러 사용, main\n",
    "    df = pd.read_csv(FILENAME)\n",
    "    df = df.drop(['Time'], axis=1)\n",
    "    n_features = df.shape[1]\n",
    "    x_train, x_test = train_test_split(df, test_size=0.9, shuffle=False)\n",
    "    #x_validation, x_test = train_test_split(x_test, test_size=0.5, shuffle=False)\n",
    "\n",
    "    x_train = data_scaling(x_train)\n",
    "    x_test = data_scaling(x_test)\n",
    "    #x_validation = data_scaling(x_validation)\n",
    "\n",
    "    x_train = data_sliding(x_train, n_features, Time_window)\n",
    "    x_test = data_sliding(x_test, n_features, Time_window)\n",
    "    #x_validation = data_sliding(x_validation, n_features, Time_window)\n",
    "\n",
    "    return x_train, x_test #, x_validation\n",
    "\n",
    "\n",
    "def sampling(inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "def vae_model(input_shape, latent_dim, kernel_size, strides, padding,act):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = layers.Conv2D(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv1\", data_format=\"channels_first\")(inputs)\n",
    "    h = layers.Conv2D(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv2\", data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2D(128, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv3\", data_format=\"channels_first\")(h)\n",
    "    shape_save = h.get_shape().as_list()\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Dense(16, activation=\"relu\")(h)\n",
    "\n",
    "    # vae\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(h)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(h)\n",
    "    z = sampling([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # decoder\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    h = layers.Dense(shape_save[1] * shape_save[2] * shape_save[3], activation=\"relu\")(latent_inputs)\n",
    "    h = layers.Reshape((shape_save[1], shape_save[2], shape_save[3]))(h)\n",
    "    h = layers.Conv2DTranspose(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2DTranspose(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1,kernel_size=kernel_size, strides=strides, padding=padding, activation=act,\n",
    "                                             data_format=\"channels_first\")(h)\n",
    "    decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    return encoder, decoder\n",
    "\n",
    "def lstm_preprocess(latent_z, seq_length):\n",
    "    reshape_num = latent_z.shape[0] - seq_length + 1\n",
    "    slide_z = sliding_window_view(latent_z, (seq_length, latent_z.shape[1]))\n",
    "    slide_z = slide_z.reshape(reshape_num, seq_length, latent_z.shape[1])\n",
    "    slide_z = slide_z[:-1]\n",
    "\n",
    "    dataY = []\n",
    "    for i in range(0, len(latent_z) - seq_length):\n",
    "        _y = latent_z[i + seq_length]  # 다음 나타날 z(정답)\n",
    "        dataY.append(_y)  # dataY 리스트에 추가\n",
    "    dataY = np.array(dataY)\n",
    "    \n",
    "    return slide_z, dataY\n",
    "    \n",
    "    \n",
    "def lstm_model(seq_length, latent_dim, lstm_z):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(seq_length, latent_dim))\n",
    "    h = layers.LSTM(32, activation=\"relu\", name='lstm1')(inputs)\n",
    "    lstm_outputs = layers.Dense(latent_dim, activation='sigmoid')(h)\n",
    "    lstm = tf.keras.Model(inputs, lstm_outputs, name='lstm')\n",
    "    lstm.compile(loss='mse', optimizer=tf.keras.optimizers.Adam())\n",
    "    lstm.fit(lstm_z, dataY, epochs=5, batch_size=256)\n",
    "    lstm_results = lstm.predict(lstm_z)\n",
    "\n",
    "    return lstm_results\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    #---------------------------------사용자 설정 변수---------------------------------------\n",
    "    FILENAME = \"BTC_USDT.csv\"\n",
    "    Time_window = 8\n",
    "    latent_dim = 2\n",
    "    #-------------------------------------------------------------------------------------\n",
    "\n",
    "    #데이터 로딩\n",
    "    x_train, x_test= data_load_processing(FILENAME, Time_window=Time_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "act = \"sigmoid\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding,act)\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=1, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "#------------------------------------------------------------------------------------------\n",
    "seq_length = 8\n",
    "\n",
    "lstm_z, dataY = lstm_preprocess(latent_z, seq_length)\n",
    "\n",
    "lstm_results = lstm_model(seq_length, latent_dim, lstm_z)\n",
    "\n",
    "decoder_output = vae.decoder.predict(lstm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           10256       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 2)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 2)            0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal (TFOpLambda)   (None, None)         0           tf.__operators__.getitem[0][0]   \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 2)            0           tf.math.exp[0][0]                \n",
      "                                                                 tf.random.normal[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 92,724\n",
      "Trainable params: 92,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1233/1233 [==============================] - 10s 6ms/step - loss: 4.0233 - reconstruction_loss: 3.8511 - kl_loss: 1.3184e-04\n",
      "Epoch 2/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7942 - reconstruction_loss: 3.7951 - kl_loss: 4.0470e-07\n",
      "Epoch 3/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7953 - reconstruction_loss: 3.7949 - kl_loss: 2.7008e-07\n",
      "Epoch 4/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7947 - reconstruction_loss: 3.7949 - kl_loss: 4.0724e-07\n",
      "Epoch 5/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7955 - reconstruction_loss: 3.7949 - kl_loss: 3.0820e-07\n",
      "Epoch 6/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7954 - reconstruction_loss: 3.7947 - kl_loss: 2.6920e-07\n",
      "Epoch 7/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7947 - reconstruction_loss: 3.7947 - kl_loss: 2.1656e-07\n",
      "Epoch 8/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7940 - reconstruction_loss: 3.7947 - kl_loss: 1.9937e-07\n",
      "Epoch 9/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7944 - reconstruction_loss: 3.7946 - kl_loss: 1.3760e-07\n",
      "Epoch 10/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7952 - reconstruction_loss: 3.7946 - kl_loss: 3.0974e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43.405698779786455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "act = \"sigmoid\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding,act)\n",
    "encoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.92028172e-01, 2.90334511e-01, 2.94325406e-01, 2.91690876e-01,\n",
       "       1.28034781e-02, 2.91970143e-01, 1.70846712e-02, 2.91319238e-01,\n",
       "       2.01296969e-02, 4.47492299e-01, 2.36533311e-01, 3.66674647e-01,\n",
       "       3.92146587e-01, 2.91061150e-01, 2.12365833e-02, 2.91134819e-01,\n",
       "       2.79011400e-02, 3.60360194e-01, 1.27683809e-01, 3.65558665e-01,\n",
       "       2.11723599e-01, 2.91124649e-01, 3.42660671e-02, 2.90319558e-01,\n",
       "       2.98881262e-02, 3.48278646e-01, 6.07620474e-02, 3.35166460e-01,\n",
       "       1.17714478e-01, 2.85898890e-01, 2.37780000e-02, 2.85868523e-01,\n",
       "       3.21074999e-02, 2.99450752e-01, 5.12985089e-02, 2.97449067e-01,\n",
       "       6.24664374e-02, 2.82898658e-01, 5.55299442e-02, 2.84263507e-01,\n",
       "       4.31056906e-02, 3.02565338e-01, 2.62291760e-02, 3.02324704e-01,\n",
       "       4.48243776e-02, 5.33293333e-01, 3.61499602e-02, 9.99928230e-01,\n",
       "       5.65686608e-01, 4.23772617e-04, 4.13801998e-01, 2.49842430e-01,\n",
       "       9.89829098e-01, 3.75898567e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.18099493e-01, 4.16757941e-01, 4.19703335e-01, 4.16076064e-01,\n",
       "       2.34368835e-02, 4.14020598e-01, 3.65704075e-02, 4.12013024e-01,\n",
       "       4.36796322e-02, 4.51304018e-01, 2.13603467e-01, 3.78624111e-01,\n",
       "       3.24392319e-01, 4.15806562e-01, 4.73525599e-02, 4.13674682e-01,\n",
       "       5.92509545e-02, 3.72370899e-01, 1.19508751e-01, 3.83469194e-01,\n",
       "       1.89862415e-01, 4.13511395e-01, 6.32721782e-02, 4.11593884e-01,\n",
       "       6.46123812e-02, 3.75601947e-01, 7.01481327e-02, 3.54057491e-01,\n",
       "       1.12239227e-01, 4.10392970e-01, 7.38411248e-02, 4.08952415e-01,\n",
       "       7.90221840e-02, 3.03779602e-01, 4.20528688e-02, 3.03779006e-01,\n",
       "       5.77551015e-02, 4.08249438e-01, 1.01201601e-01, 4.09710675e-01,\n",
       "       1.01965584e-01, 3.01319063e-01, 3.16159986e-02, 3.04298580e-01,\n",
       "       4.39890623e-02, 5.14957309e-01, 2.18226518e-02, 9.67293024e-01,\n",
       "       5.63111305e-01, 2.69506883e-04, 4.59070802e-01, 4.96765345e-01,\n",
       "       4.72669631e-01, 4.95276377e-02], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_latent_z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           10256       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_2 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_3 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 2)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli ()                   0           tf.compat.v1.shape_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_1 (TFOpLambda)      (None, 2)            0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal_1 (TFOpLambda) (None, None)         0           tf.__operators__.getitem_2[0][0] \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 2)            0           tf.math.exp_1[0][0]              \n",
      "                                                                 tf.random.normal_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 92,724\n",
      "Trainable params: 92,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 4.6940 - reconstruction_loss: 4.0187 - kl_loss: 0.0047\n",
      "Epoch 2/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7959 - reconstruction_loss: 3.7960 - kl_loss: 1.2316e-04\n",
      "Epoch 3/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7948 - reconstruction_loss: 3.7958 - kl_loss: 5.6363e-06\n",
      "Epoch 4/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7981 - reconstruction_loss: 3.7974 - kl_loss: 2.2417e-05\n",
      "Epoch 5/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7960 - reconstruction_loss: 3.7959 - kl_loss: 2.8194e-05\n",
      "Epoch 6/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7954 - reconstruction_loss: 3.7959 - kl_loss: 1.2918e-05\n",
      "Epoch 7/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7944 - reconstruction_loss: 3.7956 - kl_loss: 1.3827e-05\n",
      "Epoch 8/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7955 - reconstruction_loss: 3.7957 - kl_loss: 3.0496e-06\n",
      "Epoch 9/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7958 - reconstruction_loss: 3.7957 - kl_loss: 1.2138e-06\n",
      "Epoch 10/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7967 - reconstruction_loss: 3.7954 - kl_loss: 3.7626e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "182.5979424989267"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "act = \"tanh\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding,act)\n",
    "encoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.92028172e-01, 2.90334511e-01, 2.94325406e-01, 2.91690876e-01,\n",
       "       1.28034781e-02, 2.91970143e-01, 1.70846712e-02, 2.91319238e-01,\n",
       "       2.01296969e-02, 4.47492299e-01, 2.36533311e-01, 3.66674647e-01,\n",
       "       3.92146587e-01, 2.91061150e-01, 2.12365833e-02, 2.91134819e-01,\n",
       "       2.79011400e-02, 3.60360194e-01, 1.27683809e-01, 3.65558665e-01,\n",
       "       2.11723599e-01, 2.91124649e-01, 3.42660671e-02, 2.90319558e-01,\n",
       "       2.98881262e-02, 3.48278646e-01, 6.07620474e-02, 3.35166460e-01,\n",
       "       1.17714478e-01, 2.85898890e-01, 2.37780000e-02, 2.85868523e-01,\n",
       "       3.21074999e-02, 2.99450752e-01, 5.12985089e-02, 2.97449067e-01,\n",
       "       6.24664374e-02, 2.82898658e-01, 5.55299442e-02, 2.84263507e-01,\n",
       "       4.31056906e-02, 3.02565338e-01, 2.62291760e-02, 3.02324704e-01,\n",
       "       4.48243776e-02, 5.33293333e-01, 3.61499602e-02, 9.99928230e-01,\n",
       "       5.65686608e-01, 4.23772617e-04, 4.13801998e-01, 2.49842430e-01,\n",
       "       9.89829098e-01, 3.75898567e-02])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41766277,  0.41889974,  0.42084754,  0.4214852 ,  0.02413475,\n",
       "        0.42367056,  0.03628674,  0.42416644,  0.04411514,  0.46039099,\n",
       "        0.21106328,  0.38851222,  0.32216308,  0.42364836,  0.04456185,\n",
       "        0.425455  ,  0.05890395,  0.37977713,  0.11526326,  0.3932582 ,\n",
       "        0.18512012,  0.42150375,  0.05983473,  0.42333716,  0.06334583,\n",
       "        0.38370833,  0.06736528,  0.36373365,  0.10686415,  0.420181  ,\n",
       "        0.06938571,  0.42074898,  0.07790724,  0.31114632,  0.03963118,\n",
       "        0.31525144,  0.05633463,  0.41982535,  0.09810513,  0.42049846,\n",
       "        0.10273921,  0.31012365,  0.03128133,  0.318601  ,  0.04457743,\n",
       "        0.52423596,  0.0197697 ,  0.96816665,  0.56901735, -0.03135506,\n",
       "        0.45597643,  0.51712155,  0.4935831 ,  0.05497451], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_latent_z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           10256       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_4 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_5 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 2)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli ()                   0           tf.compat.v1.shape_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli ()                   0           tf.compat.v1.shape_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_2 (TFOpLambda)      (None, 2)            0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal_2 (TFOpLambda) (None, None)         0           tf.__operators__.getitem_4[0][0] \n",
      "                                                                 tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 2)            0           tf.math.exp_2[0][0]              \n",
      "                                                                 tf.random.normal_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 92,724\n",
      "Trainable params: 92,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1233/1233 [==============================] - 10s 8ms/step - loss: 4.5859 - reconstruction_loss: 3.9943 - kl_loss: 0.0038\n",
      "Epoch 2/10\n",
      "1233/1233 [==============================] - 9s 8ms/step - loss: 3.7974 - reconstruction_loss: 3.7960 - kl_loss: 1.4057e-04\n",
      "Epoch 3/10\n",
      "1233/1233 [==============================] - 9s 8ms/step - loss: 3.7970 - reconstruction_loss: 3.7961 - kl_loss: 4.2686e-05\n",
      "Epoch 4/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7968 - reconstruction_loss: 3.7984 - kl_loss: 2.4106e-05\n",
      "Epoch 5/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7951 - reconstruction_loss: 3.7961 - kl_loss: 1.3465e-05\n",
      "Epoch 6/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7962 - reconstruction_loss: 3.7962 - kl_loss: 2.7311e-06\n",
      "Epoch 7/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7976 - reconstruction_loss: 3.7959 - kl_loss: 4.8012e-07\n",
      "Epoch 8/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7964 - reconstruction_loss: 3.7963 - kl_loss: 7.9118e-07\n",
      "Epoch 9/10\n",
      "1233/1233 [==============================] - 9s 8ms/step - loss: 3.7956 - reconstruction_loss: 3.7956 - kl_loss: 3.4223e-07\n",
      "Epoch 10/10\n",
      "1233/1233 [==============================] - 9s 8ms/step - loss: 3.7967 - reconstruction_loss: 3.7956 - kl_loss: 5.5053e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "447.5199553432723"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "act = \"linear\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding,act)\n",
    "encoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.92028172e-01, 2.90334511e-01, 2.94325406e-01, 2.91690876e-01,\n",
       "       1.28034781e-02, 2.91970143e-01, 1.70846712e-02, 2.91319238e-01,\n",
       "       2.01296969e-02, 4.47492299e-01, 2.36533311e-01, 3.66674647e-01,\n",
       "       3.92146587e-01, 2.91061150e-01, 2.12365833e-02, 2.91134819e-01,\n",
       "       2.79011400e-02, 3.60360194e-01, 1.27683809e-01, 3.65558665e-01,\n",
       "       2.11723599e-01, 2.91124649e-01, 3.42660671e-02, 2.90319558e-01,\n",
       "       2.98881262e-02, 3.48278646e-01, 6.07620474e-02, 3.35166460e-01,\n",
       "       1.17714478e-01, 2.85898890e-01, 2.37780000e-02, 2.85868523e-01,\n",
       "       3.21074999e-02, 2.99450752e-01, 5.12985089e-02, 2.97449067e-01,\n",
       "       6.24664374e-02, 2.82898658e-01, 5.55299442e-02, 2.84263507e-01,\n",
       "       4.31056906e-02, 3.02565338e-01, 2.62291760e-02, 3.02324704e-01,\n",
       "       4.48243776e-02, 5.33293333e-01, 3.61499602e-02, 9.99928230e-01,\n",
       "       5.65686608e-01, 4.23772617e-04, 4.13801998e-01, 2.49842430e-01,\n",
       "       9.89829098e-01, 3.75898567e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40881914,  0.39995444,  0.40690887,  0.40078083,  0.02096081,\n",
       "        0.39738703,  0.03592284,  0.39897865,  0.0413378 ,  0.4335424 ,\n",
       "        0.20433599,  0.36745787,  0.3132404 ,  0.396187  ,  0.04363459,\n",
       "        0.4022055 ,  0.05569618,  0.3607217 ,  0.11077671,  0.37405246,\n",
       "        0.179897  ,  0.39961293,  0.05630418,  0.40832385,  0.05935341,\n",
       "        0.36549485,  0.06315521,  0.34677988,  0.10411687,  0.39999345,\n",
       "        0.06772111,  0.40509856,  0.07314827,  0.29394725,  0.03716065,\n",
       "        0.29879963,  0.05290093,  0.4000028 ,  0.09358127,  0.40449795,\n",
       "        0.09611005,  0.29249233,  0.02943386,  0.30217013,  0.04270905,\n",
       "        0.5113592 ,  0.02265958,  0.96486014,  0.57043505, -0.09322964,\n",
       "        0.45858902,  0.4883399 ,  0.4790087 ,  0.04133465], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_latent_z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
