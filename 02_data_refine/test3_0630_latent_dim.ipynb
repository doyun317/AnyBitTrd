{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, models, optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import vae as V\n",
    "\n",
    "def data_scaling(data):             #스케일러, main\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_sliding(data, n_features, Time_window): #데이터 밀기, main\n",
    "    # reshape_num = data.shape[0] - Time_window + 1\n",
    "    data = sliding_window_view(data, (Time_window, n_features))\n",
    "    #   data = data.reshape(reshape_num, Time_window, n_features) <-필요없음\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_load_processing(FILENAME, Time_window=None): #데이터 로딩 및 스케일러 사용, main\n",
    "    df = pd.read_csv(FILENAME)\n",
    "    df = df.drop(['Time'], axis=1)\n",
    "    n_features = df.shape[1]\n",
    "    x_train, x_test = train_test_split(df, test_size=0.9, shuffle=False)\n",
    "    #x_validation, x_test = train_test_split(x_test, test_size=0.5, shuffle=False)\n",
    "\n",
    "    x_train = data_scaling(x_train)\n",
    "    x_test = data_scaling(x_test)\n",
    "    #x_validation = data_scaling(x_validation)\n",
    "\n",
    "    x_train = data_sliding(x_train, n_features, Time_window)\n",
    "    x_test = data_sliding(x_test, n_features, Time_window)\n",
    "    #x_validation = data_sliding(x_validation, n_features, Time_window)\n",
    "\n",
    "    return x_train, x_test #, x_validation\n",
    "\n",
    "\n",
    "def sampling(inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "def vae_model(input_shape, latent_dim, kernel_size, strides, padding):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = layers.Conv2D(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv1\", data_format=\"channels_first\")(inputs)\n",
    "    h = layers.Conv2D(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv2\", data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2D(128, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                      name=\"conv3\", data_format=\"channels_first\")(h)\n",
    "    shape_save = h.get_shape().as_list()\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Dense(16, activation=\"relu\")(h)\n",
    "\n",
    "    # vae\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(h)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(h)\n",
    "    z = sampling([z_mean, z_log_var])\n",
    "    encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # decoder\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    h = layers.Dense(shape_save[1] * shape_save[2] * shape_save[3], activation=\"relu\")(latent_inputs)\n",
    "    h = layers.Reshape((shape_save[1], shape_save[2], shape_save[3]))(h)\n",
    "    h = layers.Conv2DTranspose(64, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    h = layers.Conv2DTranspose(32, kernel_size=kernel_size, strides=strides, padding=padding, activation='relu',\n",
    "                               data_format=\"channels_first\")(h)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1,kernel_size=kernel_size, strides=strides, padding=padding, activation=\"relu\",\n",
    "                                             data_format=\"channels_first\")(h)\n",
    "    decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    return encoder, decoder\n",
    "\n",
    "def lstm_preprocess(latent_z, seq_length):\n",
    "    reshape_num = latent_z.shape[0] - seq_length + 1\n",
    "    slide_z = sliding_window_view(latent_z, (seq_length, latent_z.shape[1]))\n",
    "    slide_z = slide_z.reshape(reshape_num, seq_length, latent_z.shape[1])\n",
    "    slide_z = slide_z[:-1]\n",
    "\n",
    "    dataY = []\n",
    "    for i in range(0, len(latent_z) - seq_length):\n",
    "        _y = latent_z[i + seq_length]  # 다음 나타날 z(정답)\n",
    "        dataY.append(_y)  # dataY 리스트에 추가\n",
    "    dataY = np.array(dataY)\n",
    "    \n",
    "    return slide_z, dataY\n",
    "    \n",
    "    \n",
    "def lstm_model(seq_length, latent_dim, lstm_z):\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(seq_length, latent_dim))\n",
    "    h = layers.LSTM(32, activation=\"relu\", name='lstm1')(inputs)\n",
    "    lstm_outputs = layers.Dense(latent_dim, activation='sigmoid')(h)\n",
    "    lstm = tf.keras.Model(inputs, lstm_outputs, name='lstm')\n",
    "    lstm.compile(loss='mse', optimizer=tf.keras.optimizers.Adam())\n",
    "    lstm.fit(lstm_z, dataY, epochs=5, batch_size=256)\n",
    "    lstm_results = lstm.predict(lstm_z)\n",
    "\n",
    "    return lstm_results\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    #---------------------------------사용자 설정 변수---------------------------------------\n",
    "    FILENAME = \"BTC_USDT.csv\"\n",
    "    Time_window = 8\n",
    "    latent_dim = 2\n",
    "    #-------------------------------------------------------------------------------------\n",
    "\n",
    "    #데이터 로딩\n",
    "    x_train, x_test= data_load_processing(FILENAME, Time_window=Time_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding)\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=1, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "#------------------------------------------------------------------------------------------\n",
    "seq_length = 8\n",
    "\n",
    "lstm_z, dataY = lstm_preprocess(latent_z, seq_length)\n",
    "\n",
    "lstm_results = lstm_model(seq_length, latent_dim, lstm_z)\n",
    "\n",
    "decoder_output = vae.decoder.predict(lstm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           10256       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 2)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 2)            0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal (TFOpLambda)   (None, None)         0           tf.__operators__.getitem[0][0]   \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 2)            0           tf.math.exp[0][0]                \n",
      "                                                                 tf.random.normal[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 92,724\n",
      "Trainable params: 92,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1233/1233 [==============================] - 10s 6ms/step - loss: 4.9543 - reconstruction_loss: 4.0931 - kl_loss: 0.0050\n",
      "Epoch 2/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.8019 - reconstruction_loss: 3.7983 - kl_loss: 1.6567e-04\n",
      "Epoch 3/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7955 - reconstruction_loss: 3.7958 - kl_loss: 1.2274e-05\n",
      "Epoch 4/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7954 - reconstruction_loss: 3.7963 - kl_loss: 4.2483e-06\n",
      "Epoch 5/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7970 - reconstruction_loss: 3.7965 - kl_loss: 1.3975e-05\n",
      "Epoch 6/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7953 - reconstruction_loss: 3.7960 - kl_loss: 9.8415e-06\n",
      "Epoch 7/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7951 - reconstruction_loss: 3.7960 - kl_loss: 4.0323e-06\n",
      "Epoch 8/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7962 - reconstruction_loss: 3.7962 - kl_loss: 6.8234e-07\n",
      "Epoch 9/10\n",
      "1233/1233 [==============================] - 8s 6ms/step - loss: 3.7963 - reconstruction_loss: 3.7957 - kl_loss: 4.9117e-07\n",
      "Epoch 10/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7956 - reconstruction_loss: 3.7955 - kl_loss: 4.2289e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.232808150884495"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 2\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding)\n",
    "encoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.92028172e-01, 2.90334511e-01, 2.94325406e-01, 2.91690876e-01,\n",
       "       1.28034781e-02, 2.91970143e-01, 1.70846712e-02, 2.91319238e-01,\n",
       "       2.01296969e-02, 4.47492299e-01, 2.36533311e-01, 3.66674647e-01,\n",
       "       3.92146587e-01, 2.91061150e-01, 2.12365833e-02, 2.91134819e-01,\n",
       "       2.79011400e-02, 3.60360194e-01, 1.27683809e-01, 3.65558665e-01,\n",
       "       2.11723599e-01, 2.91124649e-01, 3.42660671e-02, 2.90319558e-01,\n",
       "       2.98881262e-02, 3.48278646e-01, 6.07620474e-02, 3.35166460e-01,\n",
       "       1.17714478e-01, 2.85898890e-01, 2.37780000e-02, 2.85868523e-01,\n",
       "       3.21074999e-02, 2.99450752e-01, 5.12985089e-02, 2.97449067e-01,\n",
       "       6.24664374e-02, 2.82898658e-01, 5.55299442e-02, 2.84263507e-01,\n",
       "       4.31056906e-02, 3.02565338e-01, 2.62291760e-02, 3.02324704e-01,\n",
       "       4.48243776e-02, 5.33293333e-01, 3.61499602e-02, 9.99928230e-01,\n",
       "       5.65686608e-01, 4.23772617e-04, 4.13801998e-01, 2.49842430e-01,\n",
       "       9.89829098e-01, 3.75898567e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42252865, 0.42397496, 0.42110223, 0.42557004, 0.01773322,\n",
       "       0.42546418, 0.03094375, 0.42547044, 0.03870365, 0.46168536,\n",
       "       0.20816006, 0.3846274 , 0.32000116, 0.4220867 , 0.04146543,\n",
       "       0.4226823 , 0.05368857, 0.37973073, 0.11159979, 0.38897815,\n",
       "       0.18066993, 0.42045805, 0.05761619, 0.42210943, 0.05902191,\n",
       "       0.38305503, 0.06381229, 0.35892898, 0.10345648, 0.41967455,\n",
       "       0.06633595, 0.41975012, 0.07173923, 0.30713138, 0.03691732,\n",
       "       0.30958727, 0.05338758, 0.4176122 , 0.0928539 , 0.41606763,\n",
       "       0.0939569 , 0.30492225, 0.02844059, 0.30822995, 0.03813153,\n",
       "       0.52328897, 0.01845735, 0.97716916, 0.56466955, 0.        ,\n",
       "       0.45706686, 0.5068599 , 0.4916169 , 0.04914206], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_latent_z[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           10256       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 3)            51          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 3)            51          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_2 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_3 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 3)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli ()                   0           tf.compat.v1.shape_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_1 (TFOpLambda)      (None, 3)            0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal_1 (TFOpLambda) (None, None)         0           tf.__operators__.getitem_2[0][0] \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 3)            0           tf.math.exp_1[0][0]              \n",
      "                                                                 tf.random.normal_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 3)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 92,758\n",
      "Trainable params: 92,758\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 4.5747 - reconstruction_loss: 3.9980 - kl_loss: 0.0042\n",
      "Epoch 2/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.8001 - reconstruction_loss: 3.7974 - kl_loss: 2.3946e-04\n",
      "Epoch 3/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7995 - reconstruction_loss: 3.7978 - kl_loss: 9.2416e-05A: 2s - loss: 3.7998 - r\n",
      "Epoch 4/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7978 - reconstruction_loss: 3.7964 - kl_loss: 4.4958e-05\n",
      "Epoch 5/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7975 - reconstruction_loss: 3.7963 - kl_loss: 1.0401e-05\n",
      "Epoch 6/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7958 - reconstruction_loss: 3.7968 - kl_loss: 8.9180e-06\n",
      "Epoch 7/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7953 - reconstruction_loss: 3.7968 - kl_loss: 5.5679e-06\n",
      "Epoch 8/10\n",
      "1233/1233 [==============================] - 8s 7ms/step - loss: 3.7971 - reconstruction_loss: 3.7957 - kl_loss: 3.1238e-07\n",
      "Epoch 9/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7942 - reconstruction_loss: 3.7957 - kl_loss: 4.6250e-07\n",
      "Epoch 10/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7957 - reconstruction_loss: 3.7954 - kl_loss: 4.4305e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.59124723988586"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 3\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding)\n",
    "encoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1, 8, 54)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 4, 26)    288         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 2, 12)    16448       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 1, 5)    65664       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           10256       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 4)            68          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 4)            68          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_4 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_5 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 4)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli ()                   0           tf.compat.v1.shape_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli ()                   0           tf.compat.v1.shape_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_2 (TFOpLambda)      (None, 4)            0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal_2 (TFOpLambda) (None, None)         0           tf.__operators__.getitem_4[0][0] \n",
      "                                                                 tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 4)            0           tf.math.exp_2[0][0]              \n",
      "                                                                 tf.random.normal_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 4)            0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 92,792\n",
      "Trainable params: 92,792\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 4.6031 - reconstruction_loss: 4.0110 - kl_loss: 0.0043\n",
      "Epoch 2/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7964 - reconstruction_loss: 3.7960 - kl_loss: 2.7813e-04\n",
      "Epoch 3/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7968 - reconstruction_loss: 3.7975 - kl_loss: 8.9958e-05\n",
      "Epoch 4/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7968 - reconstruction_loss: 3.7976 - kl_loss: 2.2086e-05\n",
      "Epoch 5/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.8167 - reconstruction_loss: 3.8079 - kl_loss: 9.4982e-05\n",
      "Epoch 6/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7962 - reconstruction_loss: 3.7961 - kl_loss: 2.9470e-05\n",
      "Epoch 7/10\n",
      "1233/1233 [==============================] - 9s 8ms/step - loss: 3.7973 - reconstruction_loss: 3.7958 - kl_loss: 1.4806e-05\n",
      "Epoch 8/10\n",
      "1233/1233 [==============================] - 10s 8ms/step - loss: 3.7951 - reconstruction_loss: 3.7959 - kl_loss: 6.0357e-05\n",
      "Epoch 9/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7976 - reconstruction_loss: 3.7953 - kl_loss: 6.5616e-05\n",
      "Epoch 10/10\n",
      "1233/1233 [==============================] - 9s 7ms/step - loss: 3.7956 - reconstruction_loss: 3.7954 - kl_loss: 3.6937e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108.89255136453406"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAE_model\n",
    "latent_dim = 4\n",
    "input_shape = (1, 8, 54)\n",
    "kernel_size = (2,4)\n",
    "strides = (2,2)\n",
    "padding = \"valid\"\n",
    "encoder, decoder = vae_model(input_shape, latent_dim, kernel_size, strides, padding)\n",
    "encoder.summary()\n",
    "\n",
    "#VAE\n",
    "vae = V.VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=10, batch_size=128)\n",
    "\n",
    "z_mean_, z_log_var_, latent_z = vae.encoder.predict(x_train)\n",
    "\n",
    "decoded_latent_z = vae.decoder.predict(latent_z)\n",
    "\n",
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(x_train[0][0][0], decoded_latent_z[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## latent dim 은 크게 영향을 끼치지 않는것 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
